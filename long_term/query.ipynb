{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyw_hnswlib as hnswlib\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import re\n",
    "import string\n",
    "import plotly.express as px\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_range = range(int(\"0900\", 16), int(\"097F\", 16))\n",
    "english_range = range(int(\"0061\", 16), int(\"007A\", 16) + 1)\n",
    "punjabi_range = range(int(\"0A00\", 16), int(\"0A7F\", 16))\n",
    "gujarati_range = range(int(\"0A80\", 16), int(\"0AFF\", 16))\n",
    "telugu_range = range(int(\"0C00\", 16), int(\"0C7F\", 16))\n",
    "tamil_range = range(int(\"0B80\", 16), int(\"0BFF\", 16))\n",
    "kannada_range = range(int(\"0C80\", 16), int(\"0CFF\", 16))\n",
    "odia_range = range(int(\"0B00\", 16), int(\"0B7F\", 16))\n",
    "bengali_range = range(int(\"0980\", 16), int(\"09FF\", 16))\n",
    "\n",
    "# define a function to detect the language of a sentence\n",
    "def detect_language(sentence):\n",
    "    # count the number of characters in each language range\n",
    "    hindi_count = sum(1 for c in sentence if ord(c) in hindi_range)\n",
    "    english_count = sum(1 for c in sentence if ord(c) in english_range)\n",
    "    punjabi_count = sum(1 for c in sentence if ord(c) in punjabi_range)\n",
    "    gujarati_count = sum(1 for c in sentence if ord(c) in gujarati_range)\n",
    "    telugu_count = sum(1 for c in sentence if ord(c) in telugu_range)\n",
    "    tamil_count = sum(1 for c in sentence if ord(c) in tamil_range)\n",
    "    kannada_count = sum(1 for c in sentence if ord(c) in kannada_range)\n",
    "    odia_count = sum(1 for c in sentence if ord(c) in odia_range)\n",
    "    bengali_count = sum(1 for c in sentence if ord(c) in bengali_range)\n",
    "\n",
    "    # determine the language with the highest character count\n",
    "    language_counts = {\n",
    "        \"Hindi\": hindi_count,\n",
    "        \"English\": english_count,\n",
    "        \"Punjabi\": punjabi_count,\n",
    "        \"Gujarati\": gujarati_count,\n",
    "        \"Telugu\": telugu_count,\n",
    "        \"Tamil\": tamil_count,\n",
    "        \"Kannada\": kannada_count,\n",
    "        \"Odia\": odia_count,\n",
    "        \"Bengali\": bengali_count\n",
    "    }\n",
    "    max_count = max(language_counts.values())\n",
    "    language = [k for k, v in language_counts.items() if v == max_count][0]\n",
    "\n",
    "    return language\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_file_path = \"/home/installer/ps/long_term/my_index\"\n",
    "\n",
    "\n",
    "# Load index from binary file\n",
    "index = hnswlib.Index(space='l2', dim=768)\n",
    "index.load_index(index_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "size = sys.getsizeof(index)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# device = \"cpu\"\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_salesken = SentenceTransformer(\"salesken/similarity-eng-hin_latin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model from a pickle file\n",
    "# with open('model_salesken.pkl', 'rb') as f:\n",
    "#     model_salesken = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Save the model to a pickle file\n",
    "# with open('model_salesken.pkl', 'wb') as f:\n",
    "#     pickle.dump(model_salesken, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = pd.read_csv('data/chunk0.csv',  header = None, nrows = 1, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas dataframe\n",
    "df1 = pd.read_csv('data/chunk0.csv', usecols= [0, 21],  header = None, low_memory=False)\n",
    "df2 = pd.read_csv('data/chunk1.csv',  usecols= [0, 21], header = None, low_memory=False)\n",
    "df3 = pd.read_csv('data/chunk2.csv',  usecols= [0, 21], header = None, low_memory=False)\n",
    "df4 = pd.read_csv('data/chunk3.csv',  usecols= [0, 21], nrows = 800000, header = None, low_memory=False)\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df[[0,21]]\n",
    "df.columns = ['reg_no', 'subject_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_no</th>\n",
       "      <th>subject_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-- Se/E/2015/00001</td>\n",
       "      <td>my grievance i am uploading in pdf format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-- Se/E/2015/00002</td>\n",
       "      <td>This is in regards to Vendor Registration Appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--SEL/E/2015/00001</td>\n",
       "      <td>hjjkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--SEL/E/2015/00002</td>\n",
       "      <td>Respected Sir, SUB :Telangana State - ANTI COR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--SEL/E/2015/00003</td>\n",
       "      <td>This complaint is regarding FIR no. 347 filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799998</th>\n",
       "      <td>PMOPG/D/2016/0263471</td>\n",
       "      <td>FRANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799999</th>\n",
       "      <td>PMOPG/D/2016/0263477</td>\n",
       "      <td>NR/RAHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800000</th>\n",
       "      <td>PMOPG/D/2016/0263479</td>\n",
       "      <td>PG/SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800001</th>\n",
       "      <td>PMOPG/D/2016/0263483</td>\n",
       "      <td>FRANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800002</th>\n",
       "      <td>PMOPG/D/2016/0263491</td>\n",
       "      <td>STS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3800003 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       reg_no   \n",
       "0        -- Se/E/2015/00001    \\\n",
       "1        -- Se/E/2015/00002     \n",
       "2        --SEL/E/2015/00001     \n",
       "3        --SEL/E/2015/00002     \n",
       "4        --SEL/E/2015/00003     \n",
       "...                       ...   \n",
       "3799998  PMOPG/D/2016/0263471   \n",
       "3799999  PMOPG/D/2016/0263477   \n",
       "3800000  PMOPG/D/2016/0263479   \n",
       "3800001  PMOPG/D/2016/0263483   \n",
       "3800002  PMOPG/D/2016/0263491   \n",
       "\n",
       "                                           subject_content  \n",
       "0                my grievance i am uploading in pdf format  \n",
       "1        This is in regards to Vendor Registration Appl...  \n",
       "2        hjjkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk...  \n",
       "3        Respected Sir, SUB :Telangana State - ANTI COR...  \n",
       "4        This complaint is regarding FIR no. 347 filled...  \n",
       "...                                                    ...  \n",
       "3799998                                              FRANK  \n",
       "3799999                                            NR/RAHU  \n",
       "3800000                                             PG/SAT  \n",
       "3800001                                              FRANK  \n",
       "3800002                                                STS  \n",
       "\n",
       "[3800003 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.subject_content.to_csv(\"tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split text into lines with maximum words_per_line words per line\n",
    "def split_text_to_lines(text, words_per_line=20):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    line = []\n",
    "    for word in words:\n",
    "        line.append(word)\n",
    "        if len(line) == words_per_line:\n",
    "            lines.append(' '.join(line))\n",
    "            line = []\n",
    "    if line:\n",
    "        lines.append(' '.join(line))\n",
    "    return '\\n'.join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_wording.pkl', 'rb') as f:\n",
    "    final_wording = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess textual data by performing the following steps:\n",
    "    1. Remove punctuation\n",
    "    2. Convert text to lowercase\n",
    "    3. Remove digits and special characters\n",
    "    4. Remove extra whitespaces\n",
    "    \"\"\"\n",
    "    if not isinstance(text, (str, bytes)):\n",
    "        return text\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove digits and special characters\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Correct Roman words using the predefined dictionary\n",
    "    words = text.split()\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in final_wording:\n",
    "            words[i] = final_wording[words[i]]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.set_ef(1000)\n",
    "index.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_input_string(query):\n",
    "    query_embedding = model_salesken.encode(clean_text(query))\n",
    "    labels, distances = index.knn_query(query_embedding, k=500)\n",
    "    out  = df[df.reg_no.isin(labels[0])]\n",
    "    out[\"subject_content_cleaned\"] = out.subject_content.apply(clean_text)\n",
    "    \n",
    "        # remove empty sentences or sentences with just spaces\n",
    "    out = out.dropna(subset=[\"subject_content_cleaned\"])\n",
    "    out = out[out[\"subject_content_cleaned\"].str.strip().astype(bool)]\n",
    "    out.reset_index(drop=True, inplace = True)\n",
    "    out[\"Language\"] = out['subject_content_cleaned'].apply(detect_language)\n",
    "    print(query, str(out.Language.value_counts()))\n",
    "    print()\n",
    "\n",
    "    for col in out.columns:\n",
    "        out[col] = out[col].apply(split_text_to_lines)\n",
    "    out.to_csv(\"sample_queries/tmp/\"+query+\".csv\", index=False, lineterminator='\\r\\n\\n')\n",
    "    \n",
    "    # return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_issues = ['Lack of access to basic necessities such as food and shelter.',\n",
    "                  'Poor nutrition and health outcomes for impoverished individuals.',\n",
    "                  'Limited economic opportunities for impoverished individuals and communities.',\n",
    "                  'Rural poverty and lack of development in many areas.',\n",
    "                  'High levels of poverty among marginalized and disadvantaged groups.',\n",
    "                  'Lack of social safety net and government support for impoverished individuals.',\n",
    "                  'Challenges in accessing education and healthcare for impoverished individuals.',\n",
    "                  'Child poverty and exploitation, including child labor and trafficking.',\n",
    "                  'Homelessness and displacement due to poverty and urbanization.',\n",
    "                  'Persistent poverty in certain regions despite overall economic growth.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = ['High youth unemployment despite economic growth.',\n",
    "          'Poor quality education, especially in rural areas.',\n",
    "          'Inadequate healthcare access and system.',\n",
    "          'Women face discrimination and violence.',\n",
    "          'Widespread corruption negatively impacts economy and society.',\n",
    "          'Air and water pollution harm health.',\n",
    "          'Investment needed in roads, railways, airports.',\n",
    "          'Social discrimination based on caste persists.',\n",
    "          'Tensions from communal violence between religious groups.',\n",
    "          'Large population living in poverty.',\n",
    "          'Security threats from terrorist organizations.',\n",
    "          'Increasingly sophisticated cyber threats pose challenges.',\n",
    "          'Wealth inequality among population.',\n",
    "          'Children forced into dangerous work.',\n",
    "          'Struggle for rights and protections.',\n",
    "          'Reform needed for efficiency, transparency, accessibility.',\n",
    "          'Challenges in housing, infrastructure, and social integration.',\n",
    "          'Lack of access to digital technologies limits participation.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High youth unemployment despite economic growth. Language\n",
      "English    491\n",
      "Hindi        9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Poor quality education, especially in rural areas. Language\n",
      "English    494\n",
      "Hindi        6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Inadequate healthcare access and system. Language\n",
      "English     450\n",
      "Hindi        49\n",
      "Gujarati      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Women face discrimination and violence. Language\n",
      "English    489\n",
      "Hindi       11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Widespread corruption negatively impacts economy and society. Language\n",
      "English     476\n",
      "Hindi        23\n",
      "Gujarati      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Air and water pollution harm health. Language\n",
      "English     419\n",
      "Hindi        79\n",
      "Gujarati      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Investment needed in roads, railways, airports. Language\n",
      "English    499\n",
      "Hindi        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Social discrimination based on caste persists. Language\n",
      "English    491\n",
      "Hindi        9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tensions from communal violence between religious groups. Language\n",
      "English    487\n",
      "Hindi       13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Large population living in poverty. Language\n",
      "English    407\n",
      "Hindi       93\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Security threats from terrorist organizations. Language\n",
      "English    496\n",
      "Hindi        3\n",
      "Telugu       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Increasingly sophisticated cyber threats pose challenges. Language\n",
      "English    478\n",
      "Hindi       22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Wealth inequality among population. Language\n",
      "English    488\n",
      "Hindi       12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Children forced into dangerous work. Language\n",
      "English    499\n",
      "Hindi        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Struggle for rights and protections. Language\n",
      "English     484\n",
      "Hindi        12\n",
      "Gujarati      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Reform needed for efficiency, transparency, accessibility. Language\n",
      "English    494\n",
      "Hindi        6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Challenges in housing, infrastructure, and social integration. Language\n",
      "English     490\n",
      "Hindi         9\n",
      "Gujarati      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Lack of access to digital technologies limits participation. Language\n",
      "English    489\n",
      "Hindi       11\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in issues:\n",
    "    process_input_string(i)\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('ps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db07cf3586e4a3d517105e23490166b0186d57892d50b74d9e1d6eda510229fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
