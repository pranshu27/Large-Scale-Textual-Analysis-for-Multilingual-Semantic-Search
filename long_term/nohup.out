Traceback (most recent call last):
  File "/home/installer/ps/long_term/multilingual_semantic.py", line 38, in <module>
    import langid
ModuleNotFoundError: No module named 'langid'
Traceback (most recent call last):
  File "multilingual_semantic.py", line 287, in <module>
    translated_texts = translate_batch(batch1['subject_content_cleaned'].tolist(), name, curr_batch_size)
  File "/home/installer/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "multilingual_semantic.py", line 235, in translate_batch
    generated_tokens = model.generate(**encoded_ar)
  File "/home/installer/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/installer/.local/lib/python3.8/site-packages/transformers/generation/utils.py", line 1490, in generate
    return self.beam_search(
  File "/home/installer/.local/lib/python3.8/site-packages/transformers/generation/utils.py", line 2749, in beam_search
    outputs = self(
  File "/home/installer/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/installer/.local/lib/python3.8/site-packages/transformers/models/mbart/modeling_mbart.py", line 1368, in forward
    lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 23.53 GiB total capacity; 6.80 GiB already allocated; 35.38 MiB free; 6.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
