{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/installer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower() \n",
    "    text = text.translate (str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces in content\n",
    "    text = re.sub('[!()-[]{};:\\'\"\\,<>./?@#$%^&*_~â€“]+', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(sent):\n",
    "    arr = np.zeros(26)\n",
    "    for letter in sent:\n",
    "        if 97 <= ord(letter) <= 122:\n",
    "            # print(\"here\")\n",
    "            arr[ord(letter) - 97] += 1 \n",
    "    #arr[::-1].sort()\n",
    "    \n",
    "    return arr / np.linalg.norm(arr) #normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for chunk3.csv\n",
      "Processing for chunk6.csv\n",
      "Processing for chunk4.csv\n",
      "Processing for chunk1.csv\n",
      "Processing for chunk8.csv\n",
      "Processing for chunk7.csv\n",
      "Processing for chunk9.csv\n",
      "Processing for chunk2.csv\n",
      "Processing for chunk5.csv\n",
      "Processing for chunk0.csv\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(r\"/home/installer/ps/long_term/data\"):\n",
    "    if(f.endswith(\".csv\")):\n",
    "        print(\"Processing for \" + f)\n",
    "        df = pd.read_csv(\"/home/installer/ps/long_term/data/\"+f, header = None, low_memory=False)\n",
    "        # df = pd.read_csv(\"/home/installer //ps/long_term/data/\"+f)\n",
    "        df = df[[0,21]]\n",
    "        df.columns = ['reg_no', 'subject_content']\n",
    "        # # df = df.loc[:, ['subject_content']]\n",
    "        # print('len before: ', len(df))\n",
    "        df['subject_content_cleaned'] = df['subject_content'].apply(clean_text)\n",
    "        # # df['subject_content_tc'] = df[\"subject_content_cleaned\"].apply(lambda x: str(x).split())\n",
    "        # print('len after: ', len(df)\n",
    "        df['histograms'] = df['subject_content_cleaned'].apply(freq)\n",
    "        df.to_pickle(\"preprocessed1/\"+f.split(\".\")[0]+\".pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len before: ', len(df))\n",
    "df['subject_content_cleaned'] = df['subject_content'].apply(clean_text)\n",
    "print('len after: ', len(df))\n",
    "print()\n",
    "df.subject_content_cleaned\n",
    "df['histograms'] = df['subject_content_cleaned'].apply(freq)\n",
    "df.histograms[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[ df.histograms.map(lambda x: ~np.isnan(x).any()), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('ps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db07cf3586e4a3d517105e23490166b0186d57892d50b74d9e1d6eda510229fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
